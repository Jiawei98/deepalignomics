{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial.distance as sd\n",
    "from neighborhood import neighbor_graph, laplacian\n",
    "from correspondence import Correspondence\n",
    "from stiefel import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datareader import *\n",
    "import pandas as pd \n",
    "import os.path\n",
    "import pdb\n",
    "cuda = torch.device('cuda') \n",
    "import scipy as sp\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from random import sample\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Defines the neural network\"\"\"\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H1)\n",
    "        self.linear2 = torch.nn.Linear(H1, H2)\n",
    "        self.linear3 = torch.nn.Linear(H2, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1_sigmoid = self.linear1(x).sigmoid()\n",
    "        h2_sigmoid = self.linear2(h1_sigmoid).sigmoid()\n",
    "        y_pred = self.linear3(h2_sigmoid)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_project(x1_np, x2_np):\n",
    "    \n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # N is batch size; D_in is input dimension;\n",
    "    # H is hidden dimension; D_out is output dimension.\n",
    "    N, D_in, H1, H2, D_out = x1_np.shape[0], x1_np.shape[1], 512, 64, 3\n",
    "\n",
    "    model = Net(D_in, H1, H2, D_out)\n",
    "\n",
    "    x1 = torch.from_numpy(x1_np.astype(np.float32))\n",
    "    x2 = torch.from_numpy(x2_np.astype(np.float32))\n",
    "    print(x1.dtype)\n",
    "    \n",
    "    adj1 = neighbor_graph(x1_np, k=5)\n",
    "    adj2 = neighbor_graph(x2_np, k=5)\n",
    "\n",
    "    #corr = Correspondence(matrix=np.eye(N))\n",
    "\n",
    "    w1 = np.corrcoef(x1, x2)[0:x1.shape[0],x1.shape[0]:(x1.shape[0]+x2.shape[0])]\n",
    "    w1[abs(w1) > 0.5] = 1\n",
    "    w1[w1 != 1] = 0\n",
    "    w = np.block([[w1,adj1],\n",
    "                  [adj2,w1.T]])\n",
    "\n",
    "    L_np = laplacian(w, normed=False)\n",
    "    L = torch.from_numpy(L_np.astype(np.float32))\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.00001)\n",
    "    \n",
    "    for t in range(500):\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y1_pred = model(x1)\n",
    "        y2_pred = model(x2)\n",
    "\n",
    "        outputs = torch.cat((y1_pred, y2_pred), 0)\n",
    "        \n",
    "        # Project the output onto Stiefel Manifold\n",
    "        u, s, v = torch.svd(outputs, some=True)\n",
    "        proj_outputs = u@v.t()\n",
    "\n",
    "        # Compute and print loss\n",
    "        print(L.dtype)\n",
    "        loss = torch.trace(proj_outputs.t()@L@proj_outputs)\n",
    "        print(t, loss.item())\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        proj_outputs.retain_grad()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        # Project the (Euclidean) gradient onto the tangent space of Stiefel Manifold (to get Rimannian gradient)\n",
    "        rgrad = proj_stiefel(proj_outputs, proj_outputs.grad) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # Backpropogate the Rimannian gradient w.r.t proj_outputs\n",
    "        proj_outputs.backward(rgrad)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "    proj_outputs_np = proj_outputs.detach().numpy()\n",
    "    return proj_outputs_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of geneExp:  (1000, 3654)\n",
      "Shape of Efeature:  (3654, 41)\n",
      "(1000, 3654)\n",
      "(41, 3654)\n"
     ]
    }
   ],
   "source": [
    "Efeature = pd.read_csv('../data/efeature_filtered.csv',index_col=0)\n",
    "geneExp = pd.read_csv('../data/expMat_filtered.csv',index_col=0)\n",
    "label = pd.read_csv('../data/label_visual.csv')\n",
    "print('Shape of geneExp: ', geneExp.shape)\n",
    "print('Shape of Efeature: ', Efeature.shape)\n",
    "\n",
    "#x1_np = preprocessing.scale(np.log(geneExp+1).to_numpy())\n",
    "#x2_np = preprocessing.scale(Efeature.T.to_numpy())\n",
    "\n",
    "x1_np = np.log(geneExp+1).to_numpy()\n",
    "x2_np = preprocessing.scale(Efeature.T.to_numpy())\n",
    "\n",
    "print(x1_np.shape)\n",
    "print(x2_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "0 16.509029388427734\n",
      "torch.float32\n",
      "1 15.672364234924316\n",
      "torch.float32\n",
      "2 15.045405387878418\n",
      "torch.float32\n",
      "3 14.495298385620117\n",
      "torch.float32\n",
      "4 14.020167350769043\n",
      "torch.float32\n",
      "5 13.609445571899414\n",
      "torch.float32\n",
      "6 13.233115196228027\n",
      "torch.float32\n",
      "7 12.873891830444336\n",
      "torch.float32\n",
      "8 12.531214714050293\n",
      "torch.float32\n",
      "9 12.20956039428711\n",
      "torch.float32\n",
      "10 11.910453796386719\n",
      "torch.float32\n",
      "11 11.631485939025879\n",
      "torch.float32\n",
      "12 11.369108200073242\n",
      "torch.float32\n",
      "13 11.120898246765137\n",
      "torch.float32\n",
      "14 10.885858535766602\n",
      "torch.float32\n",
      "15 10.663627624511719\n",
      "torch.float32\n",
      "16 10.453712463378906\n",
      "torch.float32\n",
      "17 10.255171775817871\n",
      "torch.float32\n",
      "18 10.066837310791016\n",
      "torch.float32\n",
      "19 9.887600898742676\n",
      "torch.float32\n",
      "20 9.716368675231934\n",
      "torch.float32\n",
      "21 9.551756858825684\n",
      "torch.float32\n",
      "22 9.392093658447266\n",
      "torch.float32\n",
      "23 9.236048698425293\n",
      "torch.float32\n",
      "24 9.083226203918457\n",
      "torch.float32\n",
      "25 8.934130668640137\n",
      "torch.float32\n",
      "26 8.789505958557129\n",
      "torch.float32\n",
      "27 8.649728775024414\n",
      "torch.float32\n",
      "28 8.514657020568848\n",
      "torch.float32\n",
      "29 8.38382625579834\n",
      "torch.float32\n",
      "30 8.25674057006836\n",
      "torch.float32\n",
      "31 8.133018493652344\n",
      "torch.float32\n",
      "32 8.01234245300293\n",
      "torch.float32\n",
      "33 7.89439582824707\n",
      "torch.float32\n",
      "34 7.77889347076416\n",
      "torch.float32\n",
      "35 7.665700912475586\n",
      "torch.float32\n",
      "36 7.554830074310303\n",
      "torch.float32\n",
      "37 7.4461750984191895\n",
      "torch.float32\n",
      "38 7.3394341468811035\n",
      "torch.float32\n",
      "39 7.234251022338867\n",
      "torch.float32\n",
      "40 7.130465030670166\n",
      "torch.float32\n",
      "41 7.028160095214844\n",
      "torch.float32\n",
      "42 6.927471160888672\n",
      "torch.float32\n",
      "43 6.8284101486206055\n",
      "torch.float32\n",
      "44 6.730859279632568\n",
      "torch.float32\n",
      "45 6.634647846221924\n",
      "torch.float32\n",
      "46 6.539583683013916\n",
      "torch.float32\n",
      "47 6.445450305938721\n",
      "torch.float32\n",
      "48 6.352083206176758\n",
      "torch.float32\n",
      "49 6.259518623352051\n",
      "torch.float32\n",
      "50 6.16788911819458\n",
      "torch.float32\n",
      "51 6.077247619628906\n",
      "torch.float32\n",
      "52 5.987526893615723\n",
      "torch.float32\n",
      "53 5.898629188537598\n",
      "torch.float32\n",
      "54 5.810492515563965\n",
      "torch.float32\n",
      "55 5.7230610847473145\n",
      "torch.float32\n",
      "56 5.636284828186035\n",
      "torch.float32\n",
      "57 5.550157070159912\n",
      "torch.float32\n",
      "58 5.464671611785889\n",
      "torch.float32\n",
      "59 5.3797736167907715\n",
      "torch.float32\n",
      "60 5.295373439788818\n",
      "torch.float32\n",
      "61 5.211437702178955\n",
      "torch.float32\n",
      "62 5.127994537353516\n",
      "torch.float32\n",
      "63 5.045048236846924\n",
      "torch.float32\n",
      "64 4.9625701904296875\n",
      "torch.float32\n",
      "65 4.8805437088012695\n",
      "torch.float32\n",
      "66 4.79892635345459\n",
      "torch.float32\n",
      "67 4.717695236206055\n",
      "torch.float32\n",
      "68 4.636867523193359\n",
      "torch.float32\n",
      "69 4.556473255157471\n",
      "torch.float32\n",
      "70 4.476494312286377\n",
      "torch.float32\n",
      "71 4.3968825340271\n",
      "torch.float32\n",
      "72 4.317631244659424\n",
      "torch.float32\n",
      "73 4.238746166229248\n",
      "torch.float32\n",
      "74 4.1602463722229\n",
      "torch.float32\n",
      "75 4.082169532775879\n",
      "torch.float32\n",
      "76 4.004493713378906\n",
      "torch.float32\n",
      "77 3.927199125289917\n",
      "torch.float32\n",
      "78 3.850283622741699\n",
      "torch.float32\n",
      "79 3.773761749267578\n",
      "torch.float32\n",
      "80 3.6976616382598877\n",
      "torch.float32\n",
      "81 3.622002601623535\n",
      "torch.float32\n",
      "82 3.546788215637207\n",
      "torch.float32\n",
      "83 3.4720146656036377\n",
      "torch.float32\n",
      "84 3.3976986408233643\n",
      "torch.float32\n",
      "85 3.323864459991455\n",
      "torch.float32\n",
      "86 3.250542402267456\n",
      "torch.float32\n",
      "87 3.177748203277588\n",
      "torch.float32\n",
      "88 3.1055057048797607\n",
      "torch.float32\n",
      "89 3.033841133117676\n",
      "torch.float32\n",
      "90 2.9627912044525146\n",
      "torch.float32\n",
      "91 2.8923821449279785\n",
      "torch.float32\n",
      "92 2.8226447105407715\n",
      "torch.float32\n",
      "93 2.753617763519287\n",
      "torch.float32\n",
      "94 2.685333251953125\n",
      "torch.float32\n",
      "95 2.617820978164673\n",
      "torch.float32\n",
      "96 2.5511035919189453\n",
      "torch.float32\n",
      "97 2.48521089553833\n",
      "torch.float32\n",
      "98 2.4201738834381104\n",
      "torch.float32\n",
      "99 2.3560187816619873\n",
      "torch.float32\n",
      "100 2.292766571044922\n",
      "torch.float32\n",
      "101 2.2304301261901855\n",
      "torch.float32\n",
      "102 2.1690306663513184\n",
      "torch.float32\n",
      "103 2.1085896492004395\n",
      "torch.float32\n",
      "104 2.049126625061035\n",
      "torch.float32\n",
      "105 1.9906537532806396\n",
      "torch.float32\n",
      "106 1.9331822395324707\n",
      "torch.float32\n",
      "107 1.8767313957214355\n",
      "torch.float32\n",
      "108 1.8213104009628296\n",
      "torch.float32\n",
      "109 1.7669308185577393\n",
      "torch.float32\n",
      "110 1.713606357574463\n",
      "torch.float32\n",
      "111 1.661341905593872\n",
      "torch.float32\n",
      "112 1.6101462841033936\n",
      "torch.float32\n",
      "113 1.5600221157073975\n",
      "torch.float32\n",
      "114 1.5109779834747314\n",
      "torch.float32\n",
      "115 1.4630138874053955\n",
      "torch.float32\n",
      "116 1.416130542755127\n",
      "torch.float32\n",
      "117 1.3703231811523438\n",
      "torch.float32\n",
      "118 1.3255891799926758\n",
      "torch.float32\n",
      "119 1.2819230556488037\n",
      "torch.float32\n",
      "120 1.2393134832382202\n",
      "torch.float32\n",
      "121 1.1977505683898926\n",
      "torch.float32\n",
      "122 1.1572215557098389\n",
      "torch.float32\n",
      "123 1.1177079677581787\n",
      "torch.float32\n",
      "124 1.079193115234375\n",
      "torch.float32\n",
      "125 1.0416560173034668\n",
      "torch.float32\n",
      "126 1.0050750970840454\n",
      "torch.float32\n",
      "127 0.9694246649742126\n",
      "torch.float32\n",
      "128 0.9346807599067688\n",
      "torch.float32\n",
      "129 0.9008166790008545\n",
      "torch.float32\n",
      "130 0.8678023219108582\n",
      "torch.float32\n",
      "131 0.8356141448020935\n",
      "torch.float32\n",
      "132 0.804222583770752\n",
      "torch.float32\n",
      "133 0.7736014127731323\n",
      "torch.float32\n",
      "134 0.7437254786491394\n",
      "torch.float32\n",
      "135 0.7145805954933167\n",
      "torch.float32\n",
      "136 0.6862057447433472\n",
      "torch.float32\n",
      "137 0.6590253114700317\n",
      "torch.float32\n",
      "138 0.6361154913902283\n",
      "torch.float32\n",
      "139 0.6364616751670837\n",
      "torch.float32\n",
      "140 0.7046343684196472\n",
      "torch.float32\n",
      "141 0.6593621373176575\n",
      "torch.float32\n",
      "142 0.5447608232498169\n",
      "torch.float32\n",
      "143 0.5962680578231812\n",
      "torch.float32\n",
      "144 0.5243697166442871\n",
      "torch.float32\n",
      "145 0.5260474681854248\n",
      "torch.float32\n",
      "146 0.5088686943054199\n",
      "torch.float32\n",
      "147 0.46288710832595825\n",
      "torch.float32\n",
      "148 0.48692119121551514\n",
      "torch.float32\n",
      "149 0.42228972911834717\n",
      "torch.float32\n",
      "150 0.4341365098953247\n",
      "torch.float32\n",
      "151 0.41485750675201416\n",
      "torch.float32\n",
      "152 0.3753488063812256\n",
      "torch.float32\n",
      "153 0.3867310881614685\n",
      "torch.float32\n",
      "154 0.3474038243293762\n",
      "torch.float32\n",
      "155 0.3428614139556885\n",
      "torch.float32\n",
      "156 0.32952964305877686\n",
      "torch.float32\n",
      "157 0.3046046495437622\n",
      "torch.float32\n",
      "158 0.30501794815063477\n",
      "torch.float32\n",
      "159 0.27467668056488037\n",
      "torch.float32\n",
      "160 0.2705821990966797\n",
      "torch.float32\n",
      "161 0.2534984350204468\n",
      "torch.float32\n",
      "162 0.23420655727386475\n",
      "torch.float32\n",
      "163 0.2306889295578003\n",
      "torch.float32\n",
      "164 0.20844781398773193\n",
      "torch.float32\n",
      "165 0.19677549600601196\n",
      "torch.float32\n",
      "166 0.1876087784767151\n",
      "torch.float32\n",
      "167 0.16755253076553345\n",
      "torch.float32\n",
      "168 0.16005784273147583\n",
      "torch.float32\n",
      "169 0.14585435390472412\n",
      "torch.float32\n",
      "170 0.12970036268234253\n",
      "torch.float32\n",
      "171 0.12197107076644897\n",
      "torch.float32\n",
      "172 0.10615742206573486\n",
      "torch.float32\n",
      "173 0.0924951434135437\n",
      "torch.float32\n",
      "174 0.08392316102981567\n",
      "torch.float32\n",
      "175 0.06882268190383911\n",
      "torch.float32\n",
      "176 0.055166006088256836\n",
      "torch.float32\n",
      "177 0.04597735404968262\n",
      "torch.float32\n",
      "178 0.03212130069732666\n",
      "torch.float32\n",
      "179 0.018781661987304688\n",
      "torch.float32\n",
      "180 0.009056806564331055\n",
      "torch.float32\n",
      "181 -0.0037981271743774414\n",
      "torch.float32\n",
      "182 -0.017275214195251465\n",
      "torch.float32\n",
      "183 -0.02750152349472046\n",
      "torch.float32\n",
      "184 -0.038805246353149414\n",
      "torch.float32\n",
      "185 -0.052265822887420654\n",
      "torch.float32\n",
      "186 -0.06374204158782959\n",
      "torch.float32\n",
      "187 -0.07414203882217407\n",
      "torch.float32\n",
      "188 -0.08640682697296143\n",
      "torch.float32\n",
      "189 -0.09871190786361694\n",
      "torch.float32\n",
      "190 -0.10945683717727661\n",
      "torch.float32\n",
      "191 -0.12028831243515015\n",
      "torch.float32\n",
      "192 -0.1321423053741455\n",
      "torch.float32\n",
      "193 -0.1438869833946228\n",
      "torch.float32\n",
      "194 -0.15470004081726074\n",
      "torch.float32\n",
      "195 -0.16540014743804932\n",
      "torch.float32\n",
      "196 -0.1766963005065918\n",
      "torch.float32\n",
      "197 -0.18801093101501465\n",
      "torch.float32\n",
      "198 -0.1987784504890442\n",
      "torch.float32\n",
      "199 -0.20924705266952515\n",
      "torch.float32\n",
      "200 -0.21989452838897705\n",
      "torch.float32\n",
      "201 -0.2307884693145752\n",
      "torch.float32\n",
      "202 -0.24157899618148804\n",
      "torch.float32\n",
      "203 -0.2520224452018738\n",
      "torch.float32\n",
      "204 -0.26216793060302734\n",
      "torch.float32\n",
      "205 -0.2722216844558716\n",
      "torch.float32\n",
      "206 -0.2823575735092163\n",
      "torch.float32\n",
      "207 -0.29252928495407104\n",
      "torch.float32\n",
      "208 -0.3026386499404907\n",
      "torch.float32\n",
      "209 -0.3125665485858917\n",
      "torch.float32\n",
      "210 -0.32224273681640625\n",
      "torch.float32\n",
      "211 -0.3316059410572052\n",
      "torch.float32\n",
      "212 -0.34053122997283936\n",
      "torch.float32\n",
      "213 -0.34876418113708496\n",
      "torch.float32\n",
      "214 -0.3554569482803345\n",
      "torch.float32\n",
      "215 -0.3598082661628723\n",
      "torch.float32\n",
      "216 -0.3596668541431427\n",
      "torch.float32\n",
      "217 -0.36036840081214905\n",
      "torch.float32\n",
      "218 -0.3663581907749176\n",
      "torch.float32\n",
      "219 -0.3893442749977112\n",
      "torch.float32\n",
      "220 -0.40763574838638306\n",
      "torch.float32\n",
      "221 -0.41102921962738037\n",
      "torch.float32\n",
      "222 -0.40870505571365356\n",
      "torch.float32\n",
      "223 -0.41622740030288696\n",
      "torch.float32\n",
      "224 -0.4358338713645935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "225 -0.4464569687843323\n",
      "torch.float32\n",
      "226 -0.4443609118461609\n",
      "torch.float32\n",
      "227 -0.4477754235267639\n",
      "torch.float32\n",
      "228 -0.4624914824962616\n",
      "torch.float32\n",
      "229 -0.4734916090965271\n",
      "torch.float32\n",
      "230 -0.4742472469806671\n",
      "torch.float32\n",
      "231 -0.4774527847766876\n",
      "torch.float32\n",
      "232 -0.48938411474227905\n",
      "torch.float32\n",
      "233 -0.4968068301677704\n",
      "torch.float32\n",
      "234 -0.4977031946182251\n",
      "torch.float32\n",
      "235 -0.5003952980041504\n",
      "torch.float32\n",
      "236 -0.5090774297714233\n",
      "torch.float32\n",
      "237 -0.5144522190093994\n",
      "torch.float32\n",
      "238 -0.516864538192749\n",
      "torch.float32\n",
      "239 -0.5205973982810974\n",
      "torch.float32\n",
      "240 -0.529538631439209\n",
      "torch.float32\n",
      "241 -0.5342814922332764\n",
      "torch.float32\n",
      "242 -0.5388941168785095\n",
      "torch.float32\n",
      "243 -0.5467015504837036\n",
      "torch.float32\n",
      "244 -0.5560463666915894\n",
      "torch.float32\n",
      "245 -0.5613645911216736\n",
      "torch.float32\n",
      "246 -0.5651077032089233\n",
      "torch.float32\n",
      "247 -0.5706303715705872\n",
      "torch.float32\n",
      "248 -0.5766957998275757\n",
      "torch.float32\n",
      "249 -0.580296516418457\n",
      "torch.float32\n",
      "250 -0.5828105807304382\n",
      "torch.float32\n",
      "251 -0.5867911577224731\n",
      "torch.float32\n",
      "252 -0.5909326076507568\n",
      "torch.float32\n",
      "253 -0.5935063362121582\n",
      "torch.float32\n",
      "254 -0.5943082571029663\n",
      "torch.float32\n",
      "255 -0.5952250957489014\n",
      "torch.float32\n",
      "256 -0.5942745208740234\n",
      "torch.float32\n",
      "257 -0.5934117436408997\n",
      "torch.float32\n",
      "258 -0.5900761485099792\n",
      "torch.float32\n",
      "259 -0.5973944664001465\n",
      "torch.float32\n",
      "260 -0.6062583923339844\n",
      "torch.float32\n",
      "261 -0.6182547211647034\n",
      "torch.float32\n",
      "262 -0.6257737874984741\n",
      "torch.float32\n",
      "263 -0.6299076676368713\n",
      "torch.float32\n",
      "264 -0.6314354538917542\n",
      "torch.float32\n",
      "265 -0.6305617094039917\n",
      "torch.float32\n",
      "266 -0.6297357082366943\n",
      "torch.float32\n",
      "267 -0.6296995878219604\n",
      "torch.float32\n",
      "268 -0.6343715190887451\n",
      "torch.float32\n",
      "269 -0.6398822069168091\n",
      "torch.float32\n",
      "270 -0.6462949514389038\n",
      "torch.float32\n",
      "271 -0.6510133147239685\n",
      "torch.float32\n",
      "272 -0.6542692184448242\n",
      "torch.float32\n",
      "273 -0.6560059785842896\n",
      "torch.float32\n",
      "274 -0.6564153432846069\n",
      "torch.float32\n",
      "275 -0.6567202806472778\n",
      "torch.float32\n",
      "276 -0.6572574973106384\n",
      "torch.float32\n",
      "277 -0.6596673727035522\n",
      "torch.float32\n",
      "278 -0.6622852087020874\n",
      "torch.float32\n",
      "279 -0.6659659147262573\n",
      "torch.float32\n",
      "280 -0.6694221496582031\n",
      "torch.float32\n",
      "281 -0.6727913618087769\n",
      "torch.float32\n",
      "282 -0.6755567193031311\n",
      "torch.float32\n",
      "283 -0.6776282787322998\n",
      "torch.float32\n",
      "284 -0.679111897945404\n",
      "torch.float32\n",
      "285 -0.6802753806114197\n",
      "torch.float32\n",
      "286 -0.681351900100708\n",
      "torch.float32\n",
      "287 -0.682254433631897\n",
      "torch.float32\n",
      "288 -0.6831755638122559\n",
      "torch.float32\n",
      "289 -0.683775007724762\n",
      "torch.float32\n",
      "290 -0.6847862005233765\n",
      "torch.float32\n",
      "291 -0.6854281425476074\n",
      "torch.float32\n",
      "292 -0.6868114471435547\n",
      "torch.float32\n",
      "293 -0.687744140625\n",
      "torch.float32\n",
      "294 -0.6895371079444885\n",
      "torch.float32\n",
      "295 -0.6909353733062744\n",
      "torch.float32\n",
      "296 -0.6931148767471313\n",
      "torch.float32\n",
      "297 -0.6949656009674072\n",
      "torch.float32\n",
      "298 -0.6972459554672241\n",
      "torch.float32\n",
      "299 -0.699133038520813\n",
      "torch.float32\n",
      "300 -0.7010955810546875\n",
      "torch.float32\n",
      "301 -0.7027557492256165\n",
      "torch.float32\n",
      "302 -0.7044048309326172\n",
      "torch.float32\n",
      "303 -0.7058535814285278\n",
      "torch.float32\n",
      "304 -0.7072163820266724\n",
      "torch.float32\n",
      "305 -0.7084242105484009\n",
      "torch.float32\n",
      "306 -0.7095625400543213\n",
      "torch.float32\n",
      "307 -0.7106077075004578\n",
      "torch.float32\n",
      "308 -0.7116031050682068\n",
      "torch.float32\n",
      "309 -0.7124820947647095\n",
      "torch.float32\n",
      "310 -0.7132496237754822\n",
      "torch.float32\n",
      "311 -0.7137671113014221\n",
      "torch.float32\n",
      "312 -0.7140495181083679\n",
      "torch.float32\n",
      "313 -0.7136948704719543\n",
      "torch.float32\n",
      "314 -0.7128603458404541\n",
      "torch.float32\n",
      "315 -0.7103511095046997\n",
      "torch.float32\n",
      "316 -0.7075543999671936\n",
      "torch.float32\n",
      "317 -0.7016551494598389\n",
      "torch.float32\n",
      "318 -0.6996359825134277\n",
      "torch.float32\n",
      "319 -0.6965009570121765\n",
      "torch.float32\n",
      "320 -0.7042610049247742\n",
      "torch.float32\n",
      "321 -0.7119871973991394\n",
      "torch.float32\n",
      "322 -0.7205185890197754\n",
      "torch.float32\n",
      "323 -0.7248088121414185\n",
      "torch.float32\n",
      "324 -0.7254586219787598\n",
      "torch.float32\n",
      "325 -0.7234644889831543\n",
      "torch.float32\n",
      "326 -0.7200970649719238\n",
      "torch.float32\n",
      "327 -0.7181398272514343\n",
      "torch.float32\n",
      "328 -0.7167840600013733\n",
      "torch.float32\n",
      "329 -0.719973087310791\n",
      "torch.float32\n",
      "330 -0.7238355875015259\n",
      "torch.float32\n",
      "331 -0.7281942367553711\n",
      "torch.float32\n",
      "332 -0.7307270169258118\n",
      "torch.float32\n",
      "333 -0.7314882278442383\n",
      "torch.float32\n",
      "334 -0.7309015989303589\n",
      "torch.float32\n",
      "335 -0.7296419143676758\n",
      "torch.float32\n",
      "336 -0.7287575602531433\n",
      "torch.float32\n",
      "337 -0.7281135320663452\n",
      "torch.float32\n",
      "338 -0.7291797399520874\n",
      "torch.float32\n",
      "339 -0.7306841611862183\n",
      "torch.float32\n",
      "340 -0.7329427003860474\n",
      "torch.float32\n",
      "341 -0.734764814376831\n",
      "torch.float32\n",
      "342 -0.7361467480659485\n",
      "torch.float32\n",
      "343 -0.7369291186332703\n",
      "torch.float32\n",
      "344 -0.7371983528137207\n",
      "torch.float32\n",
      "345 -0.7371366024017334\n",
      "torch.float32\n",
      "346 -0.7368755340576172\n",
      "torch.float32\n",
      "347 -0.7367165684700012\n",
      "torch.float32\n",
      "348 -0.7365654706954956\n",
      "torch.float32\n",
      "349 -0.7367961406707764\n",
      "torch.float32\n",
      "350 -0.7369921207427979\n",
      "torch.float32\n",
      "351 -0.7376561164855957\n",
      "torch.float32\n",
      "352 -0.7382630109786987\n",
      "torch.float32\n",
      "353 -0.7391350865364075\n",
      "torch.float32\n",
      "354 -0.7398521304130554\n",
      "torch.float32\n",
      "355 -0.7406662702560425\n",
      "torch.float32\n",
      "356 -0.7413533329963684\n",
      "torch.float32\n",
      "357 -0.7420227527618408\n",
      "torch.float32\n",
      "358 -0.742579460144043\n",
      "torch.float32\n",
      "359 -0.7431013584136963\n",
      "torch.float32\n",
      "360 -0.7435556054115295\n",
      "torch.float32\n",
      "361 -0.7439805269241333\n",
      "torch.float32\n",
      "362 -0.7443579435348511\n",
      "torch.float32\n",
      "363 -0.7447060942649841\n",
      "torch.float32\n",
      "364 -0.7450165748596191\n",
      "torch.float32\n",
      "365 -0.7452967166900635\n",
      "torch.float32\n",
      "366 -0.7455154657363892\n",
      "torch.float32\n",
      "367 -0.7456695437431335\n",
      "torch.float32\n",
      "368 -0.7456885576248169\n",
      "torch.float32\n",
      "369 -0.7455642223358154\n",
      "torch.float32\n",
      "370 -0.7450611591339111\n",
      "torch.float32\n",
      "371 -0.7442096471786499\n",
      "torch.float32\n",
      "372 -0.742331862449646\n",
      "torch.float32\n",
      "373 -0.7399321794509888\n",
      "torch.float32\n",
      "374 -0.7350844144821167\n",
      "torch.float32\n",
      "375 -0.7312198281288147\n",
      "torch.float32\n",
      "376 -0.7245122790336609\n",
      "torch.float32\n",
      "377 -0.7260359525680542\n",
      "torch.float32\n",
      "378 -0.7277584075927734\n",
      "torch.float32\n",
      "379 -0.7373560667037964\n",
      "torch.float32\n",
      "380 -0.7443765997886658\n",
      "torch.float32\n",
      "381 -0.749154806137085\n",
      "torch.float32\n",
      "382 -0.7504541277885437\n",
      "torch.float32\n",
      "383 -0.7490506172180176\n",
      "torch.float32\n",
      "384 -0.7462155818939209\n",
      "torch.float32\n",
      "385 -0.742594838142395\n",
      "torch.float32\n",
      "386 -0.7411755919456482\n",
      "torch.float32\n",
      "387 -0.7406272292137146\n",
      "torch.float32\n",
      "388 -0.7439968585968018\n",
      "torch.float32\n",
      "389 -0.7472829818725586\n",
      "torch.float32\n",
      "390 -0.7505081295967102\n",
      "torch.float32\n",
      "391 -0.7522543668746948\n",
      "torch.float32\n",
      "392 -0.7525770664215088\n",
      "torch.float32\n",
      "393 -0.7518177032470703\n",
      "torch.float32\n",
      "394 -0.7504397034645081\n",
      "torch.float32\n",
      "395 -0.7493022680282593\n",
      "torch.float32\n",
      "396 -0.7483615875244141\n",
      "torch.float32\n",
      "397 -0.7488031387329102\n",
      "torch.float32\n",
      "398 -0.7494766712188721\n",
      "torch.float32\n",
      "399 -0.751038670539856\n",
      "torch.float32\n",
      "400 -0.7523943781852722\n",
      "torch.float32\n",
      "401 -0.7536008954048157\n",
      "torch.float32\n",
      "402 -0.7543027997016907\n",
      "torch.float32\n",
      "403 -0.7545419931411743\n",
      "torch.float32\n",
      "404 -0.7543762922286987\n",
      "torch.float32\n",
      "405 -0.7538871169090271\n",
      "torch.float32\n",
      "406 -0.7531893849372864\n",
      "torch.float32\n",
      "407 -0.7522141337394714\n",
      "torch.float32\n",
      "408 -0.751187264919281\n",
      "torch.float32\n",
      "409 -0.7497640252113342\n",
      "torch.float32\n",
      "410 -0.7483123540878296\n",
      "torch.float32\n",
      "411 -0.7464615702629089\n",
      "torch.float32\n",
      "412 -0.7449696063995361\n",
      "torch.float32\n",
      "413 -0.7443042397499084\n",
      "torch.float32\n",
      "414 -0.7449584603309631\n",
      "torch.float32\n",
      "415 -0.7477051019668579\n",
      "torch.float32\n",
      "416 -0.7509832978248596\n",
      "torch.float32\n",
      "417 -0.7541223168373108\n",
      "torch.float32\n",
      "418 -0.7554636597633362\n",
      "torch.float32\n",
      "419 -0.7551000118255615\n",
      "torch.float32\n",
      "420 -0.7533294558525085\n",
      "torch.float32\n",
      "421 -0.751610279083252\n",
      "torch.float32\n",
      "422 -0.7504631876945496\n",
      "torch.float32\n",
      "423 -0.7512379884719849\n",
      "torch.float32\n",
      "424 -0.7530471086502075\n",
      "torch.float32\n",
      "425 -0.7554950714111328\n",
      "torch.float32\n",
      "426 -0.7572388648986816\n",
      "torch.float32\n",
      "427 -0.7579939961433411\n",
      "torch.float32\n",
      "428 -0.7577972412109375\n",
      "torch.float32\n",
      "429 -0.757148027420044\n",
      "torch.float32\n",
      "430 -0.7565208673477173\n",
      "torch.float32\n",
      "431 -0.7564139366149902\n",
      "torch.float32\n",
      "432 -0.7568451166152954\n",
      "torch.float32\n",
      "433 -0.7577162981033325\n",
      "torch.float32\n",
      "434 -0.7586154937744141\n",
      "torch.float32\n",
      "435 -0.7592529058456421\n",
      "torch.float32\n",
      "436 -0.759498119354248\n",
      "torch.float32\n",
      "437 -0.7593896389007568\n",
      "torch.float32\n",
      "438 -0.7590804100036621\n",
      "torch.float32\n",
      "439 -0.7587172389030457\n",
      "torch.float32\n",
      "440 -0.7584882974624634\n",
      "torch.float32\n",
      "441 -0.7583504915237427\n",
      "torch.float32\n",
      "442 -0.7583905458450317\n",
      "torch.float32\n",
      "443 -0.7583099603652954\n",
      "torch.float32\n",
      "444 -0.7581364512443542\n",
      "torch.float32\n",
      "445 -0.7573790550231934\n",
      "torch.float32\n",
      "446 -0.7561949491500854\n",
      "torch.float32\n",
      "447 -0.753639280796051\n",
      "torch.float32\n",
      "448 -0.7508016228675842\n",
      "torch.float32\n",
      "449 -0.7456322908401489\n",
      "torch.float32\n",
      "450 -0.7427735328674316\n",
      "torch.float32\n",
      "451 -0.7382488250732422\n",
      "torch.float32\n",
      "452 -0.7414828538894653\n",
      "torch.float32\n",
      "453 -0.7446888089179993\n",
      "torch.float32\n",
      "454 -0.7522090673446655\n",
      "torch.float32\n",
      "455 -0.7573282122612\n",
      "torch.float32\n",
      "456 -0.7606813907623291\n",
      "torch.float32\n",
      "457 -0.761650800704956\n",
      "torch.float32\n",
      "458 -0.7607698440551758\n",
      "torch.float32\n",
      "459 -0.7587686777114868\n",
      "torch.float32\n",
      "460 -0.7560697793960571\n",
      "torch.float32\n",
      "461 -0.7543610334396362\n",
      "torch.float32\n",
      "462 -0.7529189586639404\n",
      "torch.float32\n",
      "463 -0.7541027665138245\n",
      "torch.float32\n",
      "464 -0.7554985284805298\n",
      "torch.float32\n",
      "465 -0.7582182884216309\n",
      "torch.float32\n",
      "466 -0.7603278160095215\n",
      "torch.float32\n",
      "467 -0.761896014213562\n",
      "torch.float32\n",
      "468 -0.7625954151153564\n",
      "torch.float32\n",
      "469 -0.7625594139099121\n",
      "torch.float32\n",
      "470 -0.762010931968689\n",
      "torch.float32\n",
      "471 -0.761156439781189\n",
      "torch.float32\n",
      "472 -0.7603662014007568\n",
      "torch.float32\n",
      "473 -0.7595772743225098\n",
      "torch.float32\n",
      "474 -0.7593801021575928\n",
      "torch.float32\n",
      "475 -0.7592400908470154\n",
      "torch.float32\n",
      "476 -0.7597673535346985\n",
      "torch.float32\n",
      "477 -0.7602649927139282\n",
      "torch.float32\n",
      "478 -0.7611204385757446\n",
      "torch.float32\n",
      "479 -0.7618129253387451\n",
      "torch.float32\n",
      "480 -0.7625194787979126\n",
      "torch.float32\n",
      "481 -0.7630411386489868\n",
      "torch.float32\n",
      "482 -0.7634401321411133\n",
      "torch.float32\n",
      "483 -0.7636996507644653\n",
      "torch.float32\n",
      "484 -0.7638552784919739\n",
      "torch.float32\n",
      "485 -0.7639278769493103\n",
      "torch.float32\n",
      "486 -0.7639377117156982\n",
      "torch.float32\n",
      "487 -0.7639060020446777\n",
      "torch.float32\n",
      "488 -0.7638327479362488\n",
      "torch.float32\n",
      "489 -0.7637312412261963\n",
      "torch.float32\n",
      "490 -0.7635722160339355\n",
      "torch.float32\n",
      "491 -0.7633812427520752\n",
      "torch.float32\n",
      "492 -0.7630660533905029\n",
      "torch.float32\n",
      "493 -0.7627034783363342\n",
      "torch.float32\n",
      "494 -0.7620858550071716\n",
      "torch.float32\n",
      "495 -0.7614123225212097\n",
      "torch.float32\n",
      "496 -0.7602221965789795\n",
      "torch.float32\n",
      "497 -0.7590939998626709\n",
      "torch.float32\n",
      "498 -0.7570719718933105\n",
      "torch.float32\n",
      "499 -0.755659818649292\n"
     ]
    }
   ],
   "source": [
    "projections = train_and_project(x1_np, x2_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1041, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projections.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adarb2</th>\n",
       "      <td>-0.017885</td>\n",
       "      <td>0.012411</td>\n",
       "      <td>-0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sst</th>\n",
       "      <td>-0.011594</td>\n",
       "      <td>0.012967</td>\n",
       "      <td>0.000829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vip</th>\n",
       "      <td>-0.019374</td>\n",
       "      <td>0.015498</td>\n",
       "      <td>-0.000188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Npy</th>\n",
       "      <td>-0.009411</td>\n",
       "      <td>0.011734</td>\n",
       "      <td>-0.009520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synpr</th>\n",
       "      <td>-0.022196</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>-0.003972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast_trough_v_short_square</th>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.022146</td>\n",
       "      <td>-0.000598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast_trough_t_short_square</th>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.017694</td>\n",
       "      <td>-0.007263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold_v_short_square</th>\n",
       "      <td>0.003939</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>-0.004537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold_i_short_square</th>\n",
       "      <td>-0.017429</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>-0.009230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold_t_short_square</th>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.017692</td>\n",
       "      <td>-0.007266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1041 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0         1         2\n",
       "Adarb2                     -0.017885  0.012411 -0.000088\n",
       "Sst                        -0.011594  0.012967  0.000829\n",
       "Vip                        -0.019374  0.015498 -0.000188\n",
       "Npy                        -0.009411  0.011734 -0.009520\n",
       "Synpr                      -0.022196  0.018100 -0.003972\n",
       "...                              ...       ...       ...\n",
       "fast_trough_v_short_square  0.003909  0.022146 -0.000598\n",
       "fast_trough_t_short_square  0.000611  0.017694 -0.007263\n",
       "threshold_v_short_square    0.003939  0.019455 -0.004537\n",
       "threshold_i_short_square   -0.017429  0.013782 -0.009230\n",
       "threshold_t_short_square    0.000610  0.017692 -0.007266\n",
       "\n",
       "[1041 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projections = pd.DataFrame(projections)\n",
    "features = geneExp.index.tolist()+Efeature.columns.tolist()\n",
    "projections.index = features\n",
    "projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections.to_csv(\"../data/deepmanreg_latent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

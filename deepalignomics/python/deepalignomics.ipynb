{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Example usage of the alignment methods in this directory:\n",
    "\n",
    "  # get your two data sets somehow\n",
    "  X,Y = gen_data(1000)\n",
    "\n",
    "  # make correspondences and/or neighbor graphs\n",
    "  corr = Correspondence(matrix=numpy.eye(1000))\n",
    "  Wx = neighbor_graph(X,k=5)\n",
    "  Wy = neighbor_graph(Y,k=5)\n",
    "\n",
    "  # a linear projector:\n",
    "  proj = Procrustes(X,Y,corr,2)  # for 2-d output\n",
    "  Xnew, Ynew = proj.project(X,Y) # or any other data you want to project\n",
    "\n",
    "  # a non-linear projector:\n",
    "  Xnew,Ynew = manifold_nonlinear(X,Y,corr,2,Wx,Wy)\n",
    "\n",
    "  # show the alignment:\n",
    "  show_alignment(Xnew,Ynew,'nonlinear manifold aln')()\n",
    "  # or just use normal pyplot functions\n",
    "'''\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from alignment import (\n",
    "    TrivialAlignment, Affine, Procrustes, CCA, CCAv2,\n",
    "    ManifoldLinear, manifold_nonlinear)\n",
    "from correspondence import Correspondence\n",
    "from distance import SquaredL2\n",
    "from neighborhood import neighbor_graph\n",
    "from synthetic_data import swiss_roll, add_noise, spiral\n",
    "from util import pairwise_error, Timer\n",
    "from viz import show_alignment\n",
    "from warping import (\n",
    "    ctw, dtw, manifold_warping_linear, manifold_warping_nonlinear)\n",
    "\n",
    "\n",
    "def gen_data(n, three_d=False):\n",
    "  t = np.linspace(0,5,n)\n",
    "  if three_d:\n",
    "    X = swiss_roll(t,lambda A: np.sin(A)**2)\n",
    "    Y = np.vstack((np.sin(t)**2,t,np.zeros(n))).T\n",
    "  else:\n",
    "    X = spiral(t)\n",
    "    Y = X[:,(1,0)]  # swap x and y axes\n",
    "  return add_noise(X,0.05), add_noise(Y,0.05)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  n = 500\n",
    "  d = 3\n",
    "  X, Y = gen_data(n, d == 3)\n",
    "  corr = Correspondence(matrix=np.eye(n))\n",
    "  Wx = neighbor_graph(X,k=5)\n",
    "  Wy = neighbor_graph(Y,k=5)\n",
    "\n",
    "  lin_aligners = (\n",
    "    ('no alignment',     lambda: TrivialAlignment(X,Y)),\n",
    "    ('affine',           lambda: Affine(X,Y,corr,d)),\n",
    "    ('procrustes',       lambda: Procrustes(X,Y,corr,d)),\n",
    "    ('cca',              lambda: CCA(X,Y,corr,d)),\n",
    "    ('cca_v2',           lambda: CCAv2(X,Y,d)),\n",
    "    ('linear manifold',  lambda: ManifoldLinear(X,Y,corr,d,Wx,Wy)),\n",
    "    ('ctw',              lambda: ctw(X,Y,d)[1]),\n",
    "    ('manifold warping', lambda: manifold_warping_linear(X,Y,d,Wx,Wy)[1]),\n",
    "  )\n",
    "\n",
    "  other_aligners = (\n",
    "    ('dtw', lambda: (X, dtw(X,Y).warp(X))),\n",
    "    ('nonlinear manifold aln',\n",
    "     lambda: manifold_nonlinear(X,Y,corr,d,Wx,Wy)),\n",
    "    ('nonlinear manifold warp',\n",
    "     lambda: manifold_warping_nonlinear(X,Y,d,Wx,Wy)[1:]),\n",
    "  )\n",
    "\n",
    "  for name, aln in lin_aligners:\n",
    "    pyplot.figure()\n",
    "    with Timer(name):\n",
    "      Xnew,Ynew = aln().project(X, Y)\n",
    "    print(' sum sq. error =', pairwise_error(Xnew, Ynew, metric=SquaredL2))\n",
    "    show_alignment(Xnew,Ynew,name)\n",
    "\n",
    "  for name, aln in other_aligners:\n",
    "    pyplot.figure()\n",
    "    with Timer(name):\n",
    "      Xnew,Ynew = aln()\n",
    "    print(' sum sq. error =', pairwise_error(Xnew, Ynew, metric=SquaredL2))\n",
    "    show_alignment(Xnew, Ynew, name)\n",
    "\n",
    "  pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvlearn.datasets import load_UCImultifeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset along with labels for digits 0 through 4\n",
    "n_class = 2\n",
    "data, labels = load_UCImultifeature(select_labeled = list(range(n_class)))\n",
    "\n",
    "# Just get the first two views of data\n",
    "m_data = data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#   n = 400\n",
    "#   d = 3\n",
    "#   X, Y = m_data[0], m_data[1][:,:76]\n",
    "#   corr = Correspondence(matrix=np.eye(n))\n",
    "#   Wx = neighbor_graph(X,k=5)\n",
    "#   Wy = neighbor_graph(Y,k=5)\n",
    "\n",
    "#   lin_aligners = (\n",
    "#     ('no alignment',     lambda: TrivialAlignment(X,Y)),\n",
    "# #     ('affine',           lambda: Affine(X,Y,corr,d)),\n",
    "# #     ('procrustes',       lambda: Procrustes(X,Y,corr,d)),\n",
    "# #     ('cca',              lambda: CCA(X,Y,corr,d)),\n",
    "# #     ('cca_v2',           lambda: CCAv2(X,Y,d)),\n",
    "#     ('linear manifold',  lambda: ManifoldLinear(X,Y,corr,d,Wx,Wy)),\n",
    "# #     ('ctw',              lambda: ctw(X,Y,d)[1]),\n",
    "# #     ('manifold warping', lambda: manifold_warping_linear(X,Y,d,Wx,Wy)[1]),\n",
    "#   )\n",
    "\n",
    "#   other_aligners = (\n",
    "# #     ('dtw', lambda: (X, dtw(X,Y).warp(X))),\n",
    "#     ('nonlinear manifold aln',\n",
    "#      lambda: manifold_nonlinear(X,Y,corr,d,Wx,Wy)),\n",
    "# #     ('nonlinear manifold warp',\n",
    "# #      lambda: manifold_warping_nonlinear(X,Y,d,Wx,Wy)[1:]),\n",
    "#   )\n",
    "\n",
    "#   for name, aln in lin_aligners:\n",
    "#     pyplot.figure()\n",
    "#     with Timer(name):\n",
    "#       Xnew,Ynew = aln().project(X, Y)\n",
    "#     print(' sum sq. error =', pairwise_error(Xnew, Ynew, metric=SquaredL2))\n",
    "# #     show_alignment(Xnew,Ynew,name)\n",
    "\n",
    "#   for name, aln in other_aligners:\n",
    "#     pyplot.figure()\n",
    "#     with Timer(name):\n",
    "#       Xnew,Ynew = aln()\n",
    "#     print(' sum sq. error =', pairwise_error(Xnew, Ynew, metric=SquaredL2))\n",
    "# #     show_alignment(Xnew, Ynew, name)\n",
    "\n",
    "#   pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = np.concatenate((Xnew, Ynew), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy as sp\n",
    "# distance_matrix = sp.spatial.distance_matrix(data_new, data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "# from sklearn.gaussian_process.kernels import RBF\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "#          \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "#          \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "# classifiers = [\n",
    "#     KNeighborsClassifier(3),\n",
    "#     SVC(kernel=\"linear\", C=0.025),\n",
    "#     SVC(gamma=2, C=1),\n",
    "#     GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "#     DecisionTreeClassifier(max_depth=5),\n",
    "#     RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "#     MLPClassifier(alpha=1, max_iter=1000),\n",
    "#     AdaBoostClassifier(),\n",
    "#     GaussianNB(),\n",
    "#     QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "# X, y = m_data[1], labels\n",
    "# linearly_separable = (X, y)\n",
    "\n",
    "# datasets = [\n",
    "# #             make_moons(noise=0.3, random_state=0),\n",
    "# #             make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "#             linearly_separable\n",
    "#             ]\n",
    "\n",
    "# # figure = plt.figure(figsize=(27, 9))\n",
    "# i = 1\n",
    "# score = []\n",
    "# # iterate over datasets\n",
    "# for ds_cnt, ds in enumerate(datasets):\n",
    "#     # preprocess dataset, split into training and test part\n",
    "#     X, y = ds\n",
    "# #     X = StandardScaler().fit_transform(X)\n",
    "#     X_train, X_test, y_train, y_test = \\\n",
    "#         train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "# #     x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "# #     y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "# #     xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "# #                          np.arange(y_min, y_max, h))\n",
    "\n",
    "# #     # just plot the dataset first\n",
    "# #     cm = plt.cm.RdBu\n",
    "# #     cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "# #     ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "# #     if ds_cnt == 0:\n",
    "# #         ax.set_title(\"Input data\")\n",
    "# #     # Plot the training points\n",
    "# #     ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "# #                edgecolors='k')\n",
    "# #     # Plot the testing points\n",
    "# #     ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "# #                edgecolors='k')\n",
    "# #     ax.set_xlim(xx.min(), xx.max())\n",
    "# #     ax.set_ylim(yy.min(), yy.max())\n",
    "# #     ax.set_xticks(())\n",
    "# #     ax.set_yticks(())\n",
    "#     i += 1\n",
    "\n",
    "#     # iterate over classifiers\n",
    "#     for name, clf in zip(names, classifiers):\n",
    "# #         ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "#         clf.fit(X_train, y_train)\n",
    "#         score.append(clf.score(X_test, y_test))\n",
    "# #         score = clf.score(X_test, y_test)\n",
    "\n",
    "# #         # Plot the decision boundary. For that, we will assign a color to each\n",
    "# #         # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "# #         if hasattr(clf, \"decision_function\"):\n",
    "# #             Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "# #         else:\n",
    "# #             Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "# #         # Put the result into a color plot\n",
    "# #         Z = Z.reshape(xx.shape)\n",
    "# #         ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "# #         # Plot the training points\n",
    "# #         ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "# #                    edgecolors='k')\n",
    "# #         # Plot the testing points\n",
    "# #         ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "# #                    edgecolors='k', alpha=0.6)\n",
    "\n",
    "# #         ax.set_xlim(xx.min(), xx.max())\n",
    "# #         ax.set_ylim(yy.min(), yy.max())\n",
    "# #         ax.set_xticks(())\n",
    "# #         ax.set_yticks(())\n",
    "# #         if ds_cnt == 0:\n",
    "# #             ax.set_title(name)\n",
    "# #         ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "# #                 size=15, horizontalalignment='right')\n",
    "#         i += 1\n",
    "\n",
    "# # plt.tight_layout()\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "  n = 76\n",
    "  d = 10\n",
    "  X, Y = m_data[0].T, m_data[1][:,:76].T\n",
    "  corr = Correspondence(matrix=np.eye(n))\n",
    "  Wx = neighbor_graph(X,k=5)\n",
    "  Wy = neighbor_graph(Y,k=5)\n",
    "\n",
    "  lin_aligners = (\n",
    "    ('no alignment',     lambda: TrivialAlignment(X,Y)),\n",
    "    ('affine',           lambda: Affine(X,Y,corr,d)),\n",
    "#     ('procrustes',       lambda: Procrustes(X,Y,corr,d)),\n",
    "#     ('cca',              lambda: CCA(X,Y,corr,d)),\n",
    "#     ('cca_v2',           lambda: CCAv2(X,Y,d)),\n",
    "#     ('linear manifold',  lambda: ManifoldLinear(X,Y,corr,d,Wx,Wy)),\n",
    "#     ('ctw',              lambda: ctw(X,Y,d)[1]),\n",
    "#     ('manifold warping', lambda: manifold_warping_linear(X,Y,d,Wx,Wy)[1]),\n",
    "  )\n",
    "\n",
    "  other_aligners = (\n",
    "#     ('dtw', lambda: (X, dtw(X,Y).warp(X))),\n",
    "#     ('nonlinear manifold aln',\n",
    "#      lambda: manifold_nonlinear(X,Y,corr,d,Wx,Wy)),\n",
    "#     ('nonlinear manifold warp',\n",
    "#      lambda: manifold_warping_nonlinear(X,Y,d,Wx,Wy)[1:]),\n",
    "  )\n",
    "\n",
    "  for name, aln in lin_aligners:\n",
    "    pyplot.figure()\n",
    "    with Timer(name):\n",
    "      Xnew,Ynew = aln().project(X, Y)\n",
    "    print(' sum sq. error =', pairwise_error(Xnew, Ynew, metric=SquaredL2))\n",
    "#     show_alignment(Xnew,Ynew,name)\n",
    "\n",
    "  for name, aln in other_aligners:\n",
    "    pyplot.figure()\n",
    "    with Timer(name):\n",
    "      Xnew,Ynew = aln()\n",
    "    print(' sum sq. error =', pairwise_error(Xnew, Ynew, metric=SquaredL2))\n",
    "#     show_alignment(Xnew, Ynew, name)\n",
    "\n",
    "  pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_new = np.concatenate((Xnew, Ynew), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "distance_matrix = sp.spatial.distance_matrix(feature_new, data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat = 1/(1+distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "#          \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "#          \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "# classifiers = [\n",
    "#     KNeighborsClassifier(3),\n",
    "#     SVC(kernel=\"linear\", C=0.025),\n",
    "#     SVC(gamma=2, C=1),\n",
    "#     GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "#     DecisionTreeClassifier(max_depth=5),\n",
    "#     RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "#     MLPClassifier(alpha=1, max_iter=1000),\n",
    "#     AdaBoostClassifier(),\n",
    "#     GaussianNB(),\n",
    "#     QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "# X, y = m_data[1], labels\n",
    "# linearly_separable = (X, y)\n",
    "\n",
    "# datasets = [\n",
    "\n",
    "#             linearly_separable\n",
    "#             ]\n",
    "\n",
    "# i = 1\n",
    "# score = []\n",
    "# # iterate over datasets\n",
    "# for ds_cnt, ds in enumerate(datasets):\n",
    "#     # preprocess dataset, split into training and test part\n",
    "#     X, y = ds\n",
    "# #     X = StandardScaler().fit_transform(X)\n",
    "#     X_train, X_test, y_train, y_test = \\\n",
    "#         train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "#     i += 1\n",
    "\n",
    "#     # iterate over classifiers\n",
    "#     for name, clf in zip(names, classifiers):\n",
    "# #         ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "#         clf.fit(X_train, y_train)\n",
    "#         score.append(clf.score(X_test, y_test))\n",
    "\n",
    "#         i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(152, 50)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(50, 100)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.out = nn.Linear(100, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        a1 = self.fc1(input_)\n",
    "        h1 = self.relu1(a1)\n",
    "        dout = self.dout(h1)\n",
    "        a2 = self.fc2(dout)\n",
    "        h2 = self.prelu(a2)\n",
    "        a3 = self.out(h2)\n",
    "        y = self.out_act(a3)\n",
    "        return y\n",
    "    \n",
    "net = Net()\n",
    "opt = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.concatenate((m_data[0], m_data[1][:,:76]), axis=1),\n",
    "                                                    np.reshape(labels, (-1, 1)),\n",
    "      test_size=0.05, random_state=73)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "#       test_size=0.20, random_state=73)\n",
    "\n",
    "X_train, y_train = map(\n",
    "      torch.tensor, (X_train, y_train)\n",
    ")\n",
    "\n",
    "# X = torch.from_numpy(\n",
    "#     np.concatenate((m_data[0], m_data[1][:,:76]), axis=1)\n",
    "# )\n",
    "# # Y = torch.from_numpy(\n",
    "# #     np.concatenate((labels, labels), axis=0)\n",
    "# # ).view(800, 1)\n",
    "# Y = torch.from_numpy(\n",
    "#     labels\n",
    "# ).view(400, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = torch.from_numpy(sim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = sim.fill_diagonal_(0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, criterion, sim, batch_size=50):\n",
    "    model.train()\n",
    "    sim = sim\n",
    "    losses = []\n",
    "    for beg_i in range(0, X_train.size(0), batch_size):\n",
    "        x_batch = X_train[beg_i:beg_i + batch_size, :]\n",
    "        y_batch = y_train[beg_i:beg_i + batch_size, :]\n",
    "        x_batch = Variable(x_batch)\n",
    "        y_batch = Variable(y_batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # (1) Forward\n",
    "        y_hat = net(x_batch.float())\n",
    "        # (2) Compute diff\n",
    "        loss = criterion(y_hat, y_batch.float())\n",
    "        reg = torch.tensor(0., requires_grad=True)\n",
    "        for name, param in net.fc1.named_parameters():\n",
    "            if 'weight' in name:\n",
    "#                 reg = torch.norm(reg + param @ sim.float() @ param.T, 2)\n",
    "                M = .5 * ((torch.eye(152) - sim).T @ (torch.eye(152) - sim)) + .5 * torch.eye(152)\n",
    "                reg = torch.norm(reg + param @ M.float() @ param.T, 2)\n",
    "                loss += reg\n",
    "#         for param in model.parameters():\n",
    "#             loss += .1 * torch.sum(torch.abs(param))\n",
    "        # (3) Compute gradients\n",
    "        loss.backward()\n",
    "        # (4) update weights\n",
    "        opt.step()        \n",
    "        losses.append(loss.data.numpy())\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "reg = torch.tensor(0., requires_grad=True)\n",
    "for name, param in net.fc1.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        reg = reg + param @ distance_matrix @ param.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_losses = []\n",
    "num_epochs = 20\n",
    "for e in range(num_epochs):\n",
    "    e_losses += train_epoch(net, opt, criterion, sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(e_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(e_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_tensor_test = torch.from_numpy(X_test).float()#.to(device)\n",
    "    net.eval()\n",
    "    yhat = net(x_tensor_test)\n",
    "    y_hat_class = np.where(yhat.cpu().numpy()<0.5, 0, 1)\n",
    "    test_accuracy = balanced_accuracy_score(y_test.reshape(-1,1), y_hat_class)\n",
    "print(\"Test Accuracy {:.2f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_tensor_test = torch.from_numpy(X_test).float()#.to(device)\n",
    "    net.eval()\n",
    "    yhat = net(x_tensor_test)\n",
    "    y_hat_class = np.where(yhat.cpu().numpy()<0.5, 0, 1)\n",
    "    test_accuracy = balanced_accuracy_score(y_test.reshape(-1,1), y_hat_class)\n",
    "print(\"Test Accuracy {:.2f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

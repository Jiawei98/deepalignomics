{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/gpfs/software/Anaconda3/lib/python3.6/site-packages')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "from distance import SquaredL2, L2\n",
    "from neighborhood import neighbor_graph, laplacian\n",
    "from correspondence import Correspondence\n",
    "from stiefel import *\n",
    "from kmedoids import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/DER-22_Single_cell_expression_raw_UMI.tsv\", sep='\\t')\n",
    "xl = pd.read_excel(\"data/DER-21_Single_cell_markergenes_UMI.xlsx\")\n",
    "\n",
    "Ex1_cols = [col for col in df.columns if 'Ex1' in col]\n",
    "In1_cols = [col for col in df.columns if 'In1' in col]\n",
    "\n",
    "Ex1 = df[Ex1_cols].loc[df.index.isin(xl['All Clusters'])]\n",
    "In1 = df[In1_cols].loc[df.index.isin(xl['All Clusters'])]\n",
    "\n",
    "# Ex1.isnull().values.any()\n",
    "\n",
    "Ex1_log = np.log2(Ex1+1)\n",
    "In1_log = np.log2(In1+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Defines the neural network\"\"\"\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H1)\n",
    "        self.linear2 = torch.nn.Linear(H1, H2)\n",
    "        self.linear3 = torch.nn.Linear(H2, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1_sigmoid = self.linear1(x).sigmoid()\n",
    "        h2_sigmoid = self.linear2(h1_sigmoid).sigmoid()\n",
    "        y_pred = self.linear3(h2_sigmoid)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in1, D_in2, H1, H2, D_out = Ex1_log.shape[0], Ex1_log.shape[1], In1_log.shape[1], 1024, 512, 3\n",
    "\n",
    "model1 = Net(D_in1, H1, H2, D_out)\n",
    "model2 = Net(D_in2, H1, H2, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'x1' (Tensor)\n",
      "Stored 'x2' (Tensor)\n"
     ]
    }
   ],
   "source": [
    "x1_np = Ex1_log.values\n",
    "x2_np = In1_log.values\n",
    "\n",
    "x1 = torch.from_numpy(x1_np)\n",
    "x2 = torch.from_numpy(x2_np)\n",
    "\n",
    "%store x1\n",
    "%store x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Laplacian of the join datasets\n",
    "adj1 = neighbor_graph(x1_np, k=5)\n",
    "adj2 = neighbor_graph(x2_np, k=5)\n",
    "\n",
    "corr = Correspondence(matrix=np.eye(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.block([[corr.matrix(),adj1],\n",
    "              [adj2, corr.matrix()]])\n",
    "\n",
    "L_np, D_np = laplacian(w, normed=True, return_diag=True)\n",
    "L = torch.from_numpy(L_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.04980313057362592\n",
      "tensor(1.0658, grad_fn=<NormBackward0>)\n",
      "1 0.05192166575489997\n",
      "tensor(1.0695, grad_fn=<NormBackward0>)\n",
      "2 0.2413292139829069\n",
      "tensor(1.6175, grad_fn=<NormBackward0>)\n",
      "3 0.061042807878783314\n",
      "tensor(1.0865, grad_fn=<NormBackward0>)\n",
      "4 0.14181981780428515\n",
      "tensor(1.3185, grad_fn=<NormBackward0>)\n",
      "5 0.1508774625749779\n",
      "tensor(1.3609, grad_fn=<NormBackward0>)\n",
      "6 0.07971493970734181\n",
      "tensor(1.1836, grad_fn=<NormBackward0>)\n",
      "7 0.0615825695855951\n",
      "tensor(1.1515, grad_fn=<NormBackward0>)\n",
      "8 0.10044740737180527\n",
      "tensor(1.2788, grad_fn=<NormBackward0>)\n",
      "9 0.110169884322798\n",
      "tensor(1.2951, grad_fn=<NormBackward0>)\n",
      "10 0.0786719779693502\n",
      "tensor(1.1818, grad_fn=<NormBackward0>)\n",
      "11 0.05191717240788632\n",
      "tensor(1.0744, grad_fn=<NormBackward0>)\n",
      "12 0.06369347724115507\n",
      "tensor(1.1100, grad_fn=<NormBackward0>)\n",
      "13 0.08680025977183697\n",
      "tensor(1.1881, grad_fn=<NormBackward0>)\n",
      "14 0.08191589209029948\n",
      "tensor(1.1755, grad_fn=<NormBackward0>)\n",
      "15 0.058539638414866965\n",
      "tensor(1.1013, grad_fn=<NormBackward0>)\n",
      "16 0.04838799048077705\n",
      "tensor(1.0727, grad_fn=<NormBackward0>)\n",
      "17 0.05982587053770383\n",
      "tensor(1.1224, grad_fn=<NormBackward0>)\n",
      "18 0.07137892052005923\n",
      "tensor(1.1670, grad_fn=<NormBackward0>)\n",
      "19 0.066591924601658\n",
      "tensor(1.1509, grad_fn=<NormBackward0>)\n",
      "20 0.05285947622068899\n",
      "tensor(1.0974, grad_fn=<NormBackward0>)\n",
      "21 0.04771937001182959\n",
      "tensor(1.0694, grad_fn=<NormBackward0>)\n",
      "22 0.05472213796928787\n",
      "tensor(1.0864, grad_fn=<NormBackward0>)\n",
      "23 0.060338049962040056\n",
      "tensor(1.1014, grad_fn=<NormBackward0>)\n",
      "24 0.055700932260101366\n",
      "tensor(1.0836, grad_fn=<NormBackward0>)\n",
      "25 0.04793279276369232\n",
      "tensor(1.0575, grad_fn=<NormBackward0>)\n",
      "26 0.04727834944756915\n",
      "tensor(1.0603, grad_fn=<NormBackward0>)\n",
      "27 0.05185416841206405\n",
      "tensor(1.0832, grad_fn=<NormBackward0>)\n",
      "28 0.05272266809847991\n",
      "tensor(1.0909, grad_fn=<NormBackward0>)\n",
      "29 0.04822768053127334\n",
      "tensor(1.0765, grad_fn=<NormBackward0>)\n",
      "30 0.04495077435120492\n",
      "tensor(1.0636, grad_fn=<NormBackward0>)\n",
      "31 0.04677380902965313\n",
      "tensor(1.0679, grad_fn=<NormBackward0>)\n",
      "32 0.04921421978437102\n",
      "tensor(1.0738, grad_fn=<NormBackward0>)\n",
      "33 0.04740109128221956\n",
      "tensor(1.0644, grad_fn=<NormBackward0>)\n",
      "34 0.04401034029642184\n",
      "tensor(1.0502, grad_fn=<NormBackward0>)\n",
      "35 0.04409834032972321\n",
      "tensor(1.0510, grad_fn=<NormBackward0>)\n",
      "36 0.04641964186021304\n",
      "tensor(1.0619, grad_fn=<NormBackward0>)\n",
      "37 0.04626065666342247\n",
      "tensor(1.0638, grad_fn=<NormBackward0>)\n",
      "38 0.043615424060216276\n",
      "tensor(1.0555, grad_fn=<NormBackward0>)\n",
      "39 0.042547906381354014\n",
      "tensor(1.0515, grad_fn=<NormBackward0>)\n",
      "40 0.044019133237060054\n",
      "tensor(1.0561, grad_fn=<NormBackward0>)\n",
      "41 0.044646274077469114\n",
      "tensor(1.0576, grad_fn=<NormBackward0>)\n",
      "42 0.042959707188692214\n",
      "tensor(1.0512, grad_fn=<NormBackward0>)\n",
      "43 0.041608447033504053\n",
      "tensor(1.0466, grad_fn=<NormBackward0>)\n",
      "44 0.042262273399190184\n",
      "tensor(1.0492, grad_fn=<NormBackward0>)\n",
      "45 0.04292871112769395\n",
      "tensor(1.0511, grad_fn=<NormBackward0>)\n",
      "46 0.041989503075803306\n",
      "tensor(1.0465, grad_fn=<NormBackward0>)\n",
      "47 0.04088034360544869\n",
      "tensor(1.0418, grad_fn=<NormBackward0>)\n",
      "48 0.041059711891104245\n",
      "tensor(1.0435, grad_fn=<NormBackward0>)\n",
      "49 0.041483490285951385\n",
      "tensor(1.0471, grad_fn=<NormBackward0>)\n",
      "50 0.04090518143018576\n",
      "tensor(1.0471, grad_fn=<NormBackward0>)\n",
      "51 0.04011586402838532\n",
      "tensor(1.0454, grad_fn=<NormBackward0>)\n",
      "52 0.04012535070097109\n",
      "tensor(1.0457, grad_fn=<NormBackward0>)\n",
      "53 0.040293471803779915\n",
      "tensor(1.0457, grad_fn=<NormBackward0>)\n",
      "54 0.03983034538672607\n",
      "tensor(1.0430, grad_fn=<NormBackward0>)\n",
      "55 0.039284547965492495\n",
      "tensor(1.0403, grad_fn=<NormBackward0>)\n",
      "56 0.03925158769547811\n",
      "tensor(1.0403, grad_fn=<NormBackward0>)\n",
      "57 0.039232256988303474\n",
      "tensor(1.0413, grad_fn=<NormBackward0>)\n",
      "58 0.038797863981867534\n",
      "tensor(1.0416, grad_fn=<NormBackward0>)\n",
      "59 0.038413289257416605\n",
      "tensor(1.0422, grad_fn=<NormBackward0>)\n",
      "60 0.03836885646662336\n",
      "tensor(1.0431, grad_fn=<NormBackward0>)\n",
      "61 0.03822202443427902\n",
      "tensor(1.0420, grad_fn=<NormBackward0>)\n",
      "62 0.037807256236080625\n",
      "tensor(1.0387, grad_fn=<NormBackward0>)\n",
      "63 0.03754100842734508\n",
      "tensor(1.0360, grad_fn=<NormBackward0>)\n",
      "64 0.03747646183262278\n",
      "tensor(1.0355, grad_fn=<NormBackward0>)\n",
      "65 0.03724118340263173\n",
      "tensor(1.0359, grad_fn=<NormBackward0>)\n",
      "66 0.03687315770062992\n",
      "tensor(1.0364, grad_fn=<NormBackward0>)\n",
      "67 0.036686291989917894\n",
      "tensor(1.0373, grad_fn=<NormBackward0>)\n",
      "68 0.036572250584645014\n",
      "tensor(1.0373, grad_fn=<NormBackward0>)\n",
      "69 0.036280520596295454\n",
      "tensor(1.0356, grad_fn=<NormBackward0>)\n",
      "70 0.03596962368929732\n",
      "tensor(1.0333, grad_fn=<NormBackward0>)\n",
      "71 0.035817101991177894\n",
      "tensor(1.0320, grad_fn=<NormBackward0>)\n",
      "72 0.035634292954357744\n",
      "tensor(1.0315, grad_fn=<NormBackward0>)\n",
      "73 0.03532466634468455\n",
      "tensor(1.0315, grad_fn=<NormBackward0>)\n",
      "74 0.03507672557546057\n",
      "tensor(1.0323, grad_fn=<NormBackward0>)\n",
      "75 0.034916309867345605\n",
      "tensor(1.0331, grad_fn=<NormBackward0>)\n",
      "76 0.03467713775835801\n",
      "tensor(1.0325, grad_fn=<NormBackward0>)\n",
      "77 0.034388750189129486\n",
      "tensor(1.0306, grad_fn=<NormBackward0>)\n",
      "78 0.03418205892214224\n",
      "tensor(1.0290, grad_fn=<NormBackward0>)\n",
      "79 0.033986790099628864\n",
      "tensor(1.0281, grad_fn=<NormBackward0>)\n",
      "80 0.033719961390443656\n",
      "tensor(1.0279, grad_fn=<NormBackward0>)\n",
      "81 0.03346921505502963\n",
      "tensor(1.0282, grad_fn=<NormBackward0>)\n",
      "82 0.03326900286206874\n",
      "tensor(1.0285, grad_fn=<NormBackward0>)\n",
      "83 0.033035557748665095\n",
      "tensor(1.0279, grad_fn=<NormBackward0>)\n",
      "84 0.03277328178885275\n",
      "tensor(1.0267, grad_fn=<NormBackward0>)\n",
      "85 0.03254868854413477\n",
      "tensor(1.0255, grad_fn=<NormBackward0>)\n",
      "86 0.03232939870135551\n",
      "tensor(1.0245, grad_fn=<NormBackward0>)\n",
      "87 0.03207616750531428\n",
      "tensor(1.0240, grad_fn=<NormBackward0>)\n",
      "88 0.03183330399482294\n",
      "tensor(1.0239, grad_fn=<NormBackward0>)\n",
      "89 0.03161086697755809\n",
      "tensor(1.0240, grad_fn=<NormBackward0>)\n",
      "90 0.031368835402874704\n",
      "tensor(1.0237, grad_fn=<NormBackward0>)\n",
      "91 0.03111916296956939\n",
      "tensor(1.0228, grad_fn=<NormBackward0>)\n",
      "92 0.0308883178572745\n",
      "tensor(1.0217, grad_fn=<NormBackward0>)\n",
      "93 0.030652022408539786\n",
      "tensor(1.0209, grad_fn=<NormBackward0>)\n",
      "94 0.030402468265817273\n",
      "tensor(1.0205, grad_fn=<NormBackward0>)\n",
      "95 0.030163929504328266\n",
      "tensor(1.0204, grad_fn=<NormBackward0>)\n",
      "96 0.02992835467092919\n",
      "tensor(1.0201, grad_fn=<NormBackward0>)\n",
      "97 0.029680620354690088\n",
      "tensor(1.0195, grad_fn=<NormBackward0>)\n",
      "98 0.02943653834482142\n",
      "tensor(1.0187, grad_fn=<NormBackward0>)\n",
      "99 0.02919906753689977\n",
      "tensor(1.0180, grad_fn=<NormBackward0>)\n",
      "100 0.028952908888241466\n",
      "tensor(1.0173, grad_fn=<NormBackward0>)\n",
      "101 0.028705668819028765\n",
      "tensor(1.0167, grad_fn=<NormBackward0>)\n",
      "102 0.028465261216100116\n",
      "tensor(1.0164, grad_fn=<NormBackward0>)\n",
      "103 0.02822011708620381\n",
      "tensor(1.0160, grad_fn=<NormBackward0>)\n",
      "104 0.02797122106724155\n",
      "tensor(1.0153, grad_fn=<NormBackward0>)\n",
      "105 0.027727759411593902\n",
      "tensor(1.0146, grad_fn=<NormBackward0>)\n",
      "106 0.02748267418465064\n",
      "tensor(1.0139, grad_fn=<NormBackward0>)\n",
      "107 0.027233013271640946\n",
      "tensor(1.0134, grad_fn=<NormBackward0>)\n",
      "108 0.026986854049955503\n",
      "tensor(1.0130, grad_fn=<NormBackward0>)\n",
      "109 0.026741017669604822\n",
      "tensor(1.0125, grad_fn=<NormBackward0>)\n",
      "110 0.026491021075453675\n",
      "tensor(1.0119, grad_fn=<NormBackward0>)\n",
      "111 0.026242674340477987\n",
      "tensor(1.0112, grad_fn=<NormBackward0>)\n",
      "112 0.0259956248074934\n",
      "tensor(1.0107, grad_fn=<NormBackward0>)\n",
      "113 0.02574525522121665\n",
      "tensor(1.0101, grad_fn=<NormBackward0>)\n",
      "114 0.02549530107673577\n",
      "tensor(1.0096, grad_fn=<NormBackward0>)\n",
      "115 0.02524680903047509\n",
      "tensor(1.0090, grad_fn=<NormBackward0>)\n",
      "116 0.024995987682814608\n",
      "tensor(1.0084, grad_fn=<NormBackward0>)\n",
      "117 0.02474484991646543\n",
      "tensor(1.0078, grad_fn=<NormBackward0>)\n",
      "118 0.024495006994443777\n",
      "tensor(1.0072, grad_fn=<NormBackward0>)\n",
      "119 0.0242435929493557\n",
      "tensor(1.0066, grad_fn=<NormBackward0>)\n",
      "120 0.02399157442700421\n",
      "tensor(1.0061, grad_fn=<NormBackward0>)\n",
      "121 0.023740496882941095\n",
      "tensor(1.0056, grad_fn=<NormBackward0>)\n",
      "122 0.023488381115265827\n",
      "tensor(1.0049, grad_fn=<NormBackward0>)\n",
      "123 0.023235597828461144\n",
      "tensor(1.0043, grad_fn=<NormBackward0>)\n",
      "124 0.022983438391539268\n",
      "tensor(1.0037, grad_fn=<NormBackward0>)\n",
      "125 0.02273056587507065\n",
      "tensor(1.0032, grad_fn=<NormBackward0>)\n",
      "126 0.022477109662138048\n",
      "tensor(1.0027, grad_fn=<NormBackward0>)\n",
      "127 0.022224020348743503\n",
      "tensor(1.0021, grad_fn=<NormBackward0>)\n",
      "128 0.021970412171371898\n",
      "tensor(1.0015, grad_fn=<NormBackward0>)\n",
      "129 0.021716333539608695\n",
      "tensor(1.0009, grad_fn=<NormBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 0.021462442429175235\n",
      "tensor(1.0003, grad_fn=<NormBackward0>)\n",
      "131 0.02120813953651994\n",
      "tensor(0.9997, grad_fn=<NormBackward0>)\n",
      "132 0.020953487273255786\n",
      "tensor(0.9992, grad_fn=<NormBackward0>)\n",
      "133 0.020698896506350845\n",
      "tensor(0.9987, grad_fn=<NormBackward0>)\n",
      "134 0.0204439636358337\n",
      "tensor(0.9980, grad_fn=<NormBackward0>)\n",
      "135 0.020188773350823808\n",
      "tensor(0.9974, grad_fn=<NormBackward0>)\n",
      "136 0.019933562787611922\n",
      "tensor(0.9968, grad_fn=<NormBackward0>)\n",
      "137 0.019678053939597026\n",
      "tensor(0.9963, grad_fn=<NormBackward0>)\n",
      "138 0.019422364825962837\n",
      "tensor(0.9957, grad_fn=<NormBackward0>)\n",
      "139 0.019166596742926145\n",
      "tensor(0.9952, grad_fn=<NormBackward0>)\n",
      "140 0.01891057747034204\n",
      "tensor(0.9946, grad_fn=<NormBackward0>)\n",
      "141 0.018654429076097614\n",
      "tensor(0.9939, grad_fn=<NormBackward0>)\n",
      "142 0.018398167739275204\n",
      "tensor(0.9934, grad_fn=<NormBackward0>)\n",
      "143 0.018141697365560983\n",
      "tensor(0.9928, grad_fn=<NormBackward0>)\n",
      "144 0.017885132739422813\n",
      "tensor(0.9923, grad_fn=<NormBackward0>)\n",
      "145 0.017628431188113997\n",
      "tensor(0.9917, grad_fn=<NormBackward0>)\n",
      "146 0.017371564394990782\n",
      "tensor(0.9911, grad_fn=<NormBackward0>)\n",
      "147 0.0171146185481148\n",
      "tensor(0.9905, grad_fn=<NormBackward0>)\n",
      "148 0.01685752739385518\n",
      "tensor(0.9899, grad_fn=<NormBackward0>)\n",
      "149 0.016600311666490578\n",
      "tensor(0.9894, grad_fn=<NormBackward0>)\n",
      "150 0.016343020275128448\n",
      "tensor(0.9888, grad_fn=<NormBackward0>)\n",
      "151 0.016085587427117645\n",
      "tensor(0.9883, grad_fn=<NormBackward0>)\n",
      "152 0.015828064053548016\n",
      "tensor(0.9876, grad_fn=<NormBackward0>)\n",
      "153 0.015570461210502484\n",
      "tensor(0.9870, grad_fn=<NormBackward0>)\n",
      "154 0.015312731881132496\n",
      "tensor(0.9865, grad_fn=<NormBackward0>)\n",
      "155 0.015054938060905215\n",
      "tensor(0.9860, grad_fn=<NormBackward0>)\n",
      "156 0.014797057937932123\n",
      "tensor(0.9854, grad_fn=<NormBackward0>)\n",
      "157 0.014539074467463511\n",
      "tensor(0.9848, grad_fn=<NormBackward0>)\n",
      "158 0.01428103952027586\n",
      "tensor(0.9842, grad_fn=<NormBackward0>)\n",
      "159 0.014022915176977624\n",
      "tensor(0.9836, grad_fn=<NormBackward0>)\n",
      "160 0.013764713218185329\n",
      "tensor(0.9831, grad_fn=<NormBackward0>)\n",
      "161 0.013506462910844147\n",
      "tensor(0.9825, grad_fn=<NormBackward0>)\n",
      "162 0.0132481278567982\n",
      "tensor(0.9820, grad_fn=<NormBackward0>)\n",
      "163 0.012989737645951419\n",
      "tensor(0.9814, grad_fn=<NormBackward0>)\n",
      "164 0.012731296514655918\n",
      "tensor(0.9808, grad_fn=<NormBackward0>)\n",
      "165 0.01247278320058881\n",
      "tensor(0.9802, grad_fn=<NormBackward0>)\n",
      "166 0.0122142299154612\n",
      "tensor(0.9797, grad_fn=<NormBackward0>)\n",
      "167 0.011955622845577094\n",
      "tensor(0.9791, grad_fn=<NormBackward0>)\n",
      "168 0.011696960656353145\n",
      "tensor(0.9785, grad_fn=<NormBackward0>)\n",
      "169 0.01143826480058191\n",
      "tensor(0.9779, grad_fn=<NormBackward0>)\n",
      "170 0.011179516928740321\n",
      "tensor(0.9774, grad_fn=<NormBackward0>)\n",
      "171 0.010920730446474\n",
      "tensor(0.9768, grad_fn=<NormBackward0>)\n",
      "172 0.010661910517986165\n",
      "tensor(0.9763, grad_fn=<NormBackward0>)\n",
      "173 0.01040304658948367\n",
      "tensor(0.9757, grad_fn=<NormBackward0>)\n",
      "174 0.01014415506399266\n",
      "tensor(0.9751, grad_fn=<NormBackward0>)\n",
      "175 0.00988522989323827\n",
      "tensor(0.9746, grad_fn=<NormBackward0>)\n",
      "176 0.009626272491272347\n",
      "tensor(0.9740, grad_fn=<NormBackward0>)\n",
      "177 0.009367292091790588\n",
      "tensor(0.9734, grad_fn=<NormBackward0>)\n",
      "178 0.00910828136038666\n",
      "tensor(0.9729, grad_fn=<NormBackward0>)\n",
      "179 0.00884924864202323\n",
      "tensor(0.9723, grad_fn=<NormBackward0>)\n",
      "180 0.008590194231985301\n",
      "tensor(0.9717, grad_fn=<NormBackward0>)\n",
      "181 0.00833111684407295\n",
      "tensor(0.9712, grad_fn=<NormBackward0>)\n",
      "182 0.008072023455379967\n",
      "tensor(0.9706, grad_fn=<NormBackward0>)\n",
      "183 0.007812910716490817\n",
      "tensor(0.9701, grad_fn=<NormBackward0>)\n",
      "184 0.007553782985830523\n",
      "tensor(0.9695, grad_fn=<NormBackward0>)\n",
      "185 0.007294641895401716\n",
      "tensor(0.9689, grad_fn=<NormBackward0>)\n",
      "186 0.00703548677567932\n",
      "tensor(0.9684, grad_fn=<NormBackward0>)\n",
      "187 0.006776322230408666\n",
      "tensor(0.9678, grad_fn=<NormBackward0>)\n",
      "188 0.006517146896235768\n",
      "tensor(0.9673, grad_fn=<NormBackward0>)\n",
      "189 0.006257963783462897\n",
      "tensor(0.9667, grad_fn=<NormBackward0>)\n",
      "190 0.005998774224288891\n",
      "tensor(0.9662, grad_fn=<NormBackward0>)\n",
      "191 0.005739578394325401\n",
      "tensor(0.9656, grad_fn=<NormBackward0>)\n",
      "192 0.005480379487686857\n",
      "tensor(0.9651, grad_fn=<NormBackward0>)\n",
      "193 0.00522117693773555\n",
      "tensor(0.9645, grad_fn=<NormBackward0>)\n",
      "194 0.0049619733257644655\n",
      "tensor(0.9639, grad_fn=<NormBackward0>)\n",
      "195 0.00470276960376971\n",
      "tensor(0.9634, grad_fn=<NormBackward0>)\n",
      "196 0.004443566503468374\n",
      "tensor(0.9628, grad_fn=<NormBackward0>)\n",
      "197 0.00418436639504198\n",
      "tensor(0.9623, grad_fn=<NormBackward0>)\n",
      "198 0.003925169210788698\n",
      "tensor(0.9617, grad_fn=<NormBackward0>)\n",
      "199 0.0036659772182865147\n",
      "tensor(0.9612, grad_fn=<NormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Construct an Optimizer\n",
    "params = list(model1.parameters()) + list(model2.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr = 0.00001)\n",
    "\n",
    "for t in range(200):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y1_pred = model1(x1)\n",
    "    y2_pred = model2(x2)\n",
    "    \n",
    "    outputs = torch.cat((y1_pred, y2_pred), 0)\n",
    "    \n",
    "    # Project the output onto Stiefel Manifold\n",
    "    u, s, v = torch.svd(outputs, some=True)\n",
    "    proj_outputs = u@v.t()\n",
    "    \n",
    "    # Compute and print loss\n",
    "    loss = torch.trace(proj_outputs.t()@L@proj_outputs)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    proj_outputs.retain_grad()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    \n",
    "    # Project the (Euclidean) gradient onto the tangent space of Stiefel Manifold (to get Rimannian gradient)\n",
    "    rgrad = proj_stiefel(proj_outputs, proj_outputs.grad)\n",
    "    grd = torch.norm(rgrad)\n",
    "    print(torch.norm(rgrad))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    # Backpropogate the Rimannian gradient w.r.t proj_outputs\n",
    "    proj_outputs.backward(rgrad)\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_outputs_np = proj_outputs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'proj_outputs_np' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store proj_outputs_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/proj_outputs_np.npy', proj_outputs_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pairwise_distances(proj_outputs_np, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02997048,  0.00974398, -0.01351445],\n",
       "       [-0.00858181, -0.0060294 ,  0.03141839],\n",
       "       [-0.01719308,  0.00673225,  0.00134394],\n",
       "       ...,\n",
       "       [-0.02241915,  0.00891299, -0.0099177 ],\n",
       "       [-0.01241028,  0.00113306,  0.00084057],\n",
       "       [-0.01583905,  0.00273086, -0.00224224]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_outputs_np[1768:3536]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
